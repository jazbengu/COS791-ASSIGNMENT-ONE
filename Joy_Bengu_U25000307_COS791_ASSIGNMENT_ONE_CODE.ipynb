{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVzg6T98zFtiCNUybOABV+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZPwD4edTIMV1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage import data, img_as_float, exposure\n",
        "from skimage.filters import unsharp_mask\n",
        "\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_images(folder_path):\n",
        "  images = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
        "      image_path = os.path.join(folder_path, filename)\n",
        "      if os.path.isfile(image_path):\n",
        "        try:\n",
        "          img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
        "          if img is None:\n",
        "            print(f\"Error loading image {filename}\")\n",
        "            continue\n",
        "          images.append(img)\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing image {filename}: {e}\")\n",
        "  return images\n"
      ],
      "metadata": {
        "id": "zmE16-oe9G4U"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image tecnique implementation\n",
        "\n",
        "def gamma_correction(image, gamma):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  org_imag_float = img_as_float(image)\n",
        "  img_gamma = exposure.adjust_gamma(org_imag_float, gamma) # display(Image.fromarray((gamma_corrected * 255).astype(np.uint8)))\n",
        "  return (img_gamma*255).astype(np.uint8)\n",
        "\n",
        "def gaussian_blur(image, sigma):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  return cv2.GaussianBlur(image, (5,5), sigma)\n",
        "\n",
        "\n",
        "def unsharp_masking(image, amount):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  org_img = img_as_float(image) #this is done unsharp_mask expects float type image\n",
        "  img_unsharp = unsharp_mask(org_img, amount)\n",
        "  return (img_unsharp * 255).astype(np.uint8)\n",
        "\n",
        "def histogram_equalisation(image):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  return cv2.equalizeHist(image)\n",
        "\n",
        "\n",
        "def contrast_stretching(image):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  min_val = np.min(image)\n",
        "  max_val = np.max(image)\n",
        "\n",
        "  if  max_val-min_val==0:\n",
        "    return image.copy()\n",
        "\n",
        "  con_image = ((image - min_val) / (max_val - min_val)) * 255\n",
        "\n",
        "  return con_image.astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "UU99DeXgq5Bo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "technique_dict = {\n",
        "    \"Gamma Correction\": {\"gamma\": lambda: random.uniform(0.5, 2.0)},\n",
        "    \"Gaussian Blur\": {\"sigma\": lambda: random.uniform(0.5, 5.0)},\n",
        "    \"Unsharp Masking\": {\"amount\": lambda: random.uniform(0.5, 2.0)},\n",
        "    \"Histogram Equalisation\": {},\n",
        "    \"Contrast Stretching\": {},\n",
        "}"
      ],
      "metadata": {
        "id": "pEAwH0VIIWp8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "def ran_pipeline(min_len=4, max_len=5):\n",
        "  len = random.randint(min_len, max_len)\n",
        "  pipeline = []\n",
        "  img_tech = list(technique_dict.keys()) #this will get and use the keys from the dictionary technique_dict\n",
        "  for x in range(len):\n",
        "    tech = random.choice(img_tech)\n",
        "    params = technique_dict[tech]\n",
        "    pipeline.append({\"tech\":tech, \"params\":params})\n",
        "  return pipeline"
      ],
      "metadata": {
        "id": "3cGc4rqrJIX_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_pipeline(pipeline, image):\n",
        "  if image is None:\n",
        "    print(\"Image not found\")\n",
        "    return None\n",
        "  img_enhanced = image.copy()\n",
        "\n",
        "  for step in pipeline:\n",
        "    tech = step[\"tech\"]\n",
        "    if tech == \"Gamma Correction\":\n",
        "      img_enhanced = gamma_correction(img_enhanced, step[\"params\"][\"gamma\"]())\n",
        "    elif tech == \"Gaussian Blur\":\n",
        "      img_enhanced = gaussian_blur(img_enhanced, step[\"params\"][\"sigma\"]())\n",
        "    elif tech == \"Unsharp Masking\":\n",
        "      img_enhanced = unsharp_masking(img_enhanced, step[\"params\"][\"amount\"]())\n",
        "    elif tech == \"Histogram Equalisation\":\n",
        "      img_enhanced = histogram_equalisation(img_enhanced)\n",
        "    elif tech == \"Contrast Stretching\":\n",
        "      img_enhanced = contrast_stretching(img_enhanced)\n",
        "  return np.clip(img_enhanced,0,255).astype(np.uint8)\n",
        "\n"
      ],
      "metadata": {
        "id": "mKLdGaYrxmB4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitness Function\n",
        "def fitness_function(population, train_output,train_input):\n",
        "  fit_scores = []\n",
        "\n",
        "  if len(train_input)!= len(train_output):\n",
        "    raise ValueError(\"Number of training input images must match training output images.\")\n",
        "  if not train_output:\n",
        "    print(\"There are no training images provided\")\n",
        "    return []\n",
        "\n",
        "  for pipeline in population:\n",
        "    pipeline_final_score = 0.0\n",
        "    for x in range(len(train_output)):\n",
        "      output_image = train_output[x]\n",
        "      input_image = train_input[x]\n",
        "      image_enhance = image_to_pipeline(pipeline, input_image)\n",
        "      current_score = psnr(output_image, image_enhance,data_range=255) + ssim(output_image, image_enhance,data_range=255)\n",
        "      pipeline_final_score+=current_score\n",
        "\n",
        "    avg_fit = pipeline_final_score / len(train_output)\n",
        "    fit_scores.append(avg_fit)\n",
        "  return fit_scores\n"
      ],
      "metadata": {
        "id": "TsQOxz1GmubC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Population Random\n",
        "def random_population(pop_size):\n",
        "  population = []\n",
        "  for x in range(pop_size):\n",
        "    population.append(ran_pipeline())\n",
        "  return population\n",
        "\n"
      ],
      "metadata": {
        "id": "86tlk5Snmyg9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#selection --> tournment selction will be used\n",
        "def select_parents(population,fitnesses, k=3):\n",
        "  select_individuals = random.sample(range(len(population)), k)\n",
        "  best_individuals = max(select_individuals, key=lambda x: fitnesses[x])\n",
        "  return population[best_individuals]\n"
      ],
      "metadata": {
        "id": "KOx9kSnAsfMt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crossover\n",
        "def crossover(parent1, parent2,cross_rate):\n",
        "  if len(parent1) < 2 or len(parent2) < 2:\n",
        "    return parent1.copy(), parent2.copy()\n",
        "\n",
        "    section_1 = random.randint(0, len(parent1) - 1)\n",
        "    section_2 = random.randint(0, len(parent2) - 1)\n",
        "\n",
        "    offspring1 = parent1[:section_1] + parent2[section_1:]\n",
        "    offspring2 = parent2[:section_2] + parent1[section_2:]\n",
        "\n",
        "    return offspring1, offspring2"
      ],
      "metadata": {
        "id": "l_6VPPWg39J3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mutation\n",
        "def mutation(offspring, mutate_rate):\n",
        "  pass"
      ],
      "metadata": {
        "id": "vMI1wxSN37ve"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GA LOOP\n",
        "def run_GA(train_input,train_output,pop_size, gens, cross_rate, mutate_rate):\n",
        "  population = random_population(pop_size)\n",
        "  pop_fit = fitness_function(population, train_output,train_input)\n",
        "  for x in range(gens):\n",
        "    offspring = []\n",
        "\n",
        "    for y in range(pop_size//2):\n",
        "      parent1, parent2 = select_parents()\n",
        "      offspring1, offspring2 = crossover(parent1, parent2,cross_rate)\n",
        "      offspring1 = mutation(offspring1,mutate_rate)\n",
        "      offspring2 = mutation(offspring2,mutate_rate)\n",
        "      offspring.append(offspring1)\n",
        "      offspring.append(offspring2)\n",
        "\n",
        "\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "l1y-7rz9nHTV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VNS"
      ],
      "metadata": {
        "id": "gercHsxnnIw5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main\n",
        "if __name__ == \"__main__\":\n",
        "  seed_value = 42\n",
        "  pop_size = 30\n",
        "  gens = 100\n",
        "  cross_rate = 0.8\n",
        "  mutate_rate = 0.2\n",
        "\n",
        "  train_input_pics = extract_images(\"/content/drive/MyDrive/COS791 ASSIGNMENT ONE DATA/Test_data\")\n",
        "  train_output_pics = extract_images(\"/content/drive/MyDrive/COS791 ASSIGNMENT ONE DATA/Training_data\")\n",
        "\n",
        "  print(\"Beginning with GA optimization\")\n",
        "  best_ga_pipeline, best_ga_fitness = run_GA(train_input_pics,train_output_pics,pop_size,gens,cross_rate,mutate_rate)\n",
        "  print(\"Genetic Algorithm optimization completed.\")\n",
        "  print(f\"Best GA pipeline found: {best_ga_pipeline}\")\n",
        "  print(f\"Best GA fitness score: {best_ga_fitness}\")\n",
        "\n",
        "  print(\"\\nBeginning with VNS optimization\")\n",
        "  #best_vns_pipeline, best_vns_fitness = run_VNS(train_input_pics,train_output_pics,pop_size,gens,cross_rate,mutate_rate)\n"
      ],
      "metadata": {
        "id": "eIqUao4XrWFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "8794c322-b36b-48ea-a46d-aca94d9adbae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning with GA optimization\n",
            "There are no training images provided\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "select_parents() missing 2 required positional arguments: 'population' and 'fitnesses'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1966672103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beginning with GA optimization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mbest_ga_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ga_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_GA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_pics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_output_pics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmutate_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Genetic Algorithm optimization completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best GA pipeline found: {best_ga_pipeline}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3542768774.py\u001b[0m in \u001b[0;36mrun_GA\u001b[0;34m(train_input, train_output, pop_size, gens, cross_rate, mutate_rate)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mparent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0moffspring1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moffspring1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffspring1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmutate_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: select_parents() missing 2 required positional arguments: 'population' and 'fitnesses'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5A0tONzo78kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1b9018d"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}